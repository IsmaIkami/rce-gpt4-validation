{
  "task_family": "f10_confidence_calibration",
  "total_queries": 5,
  "queries": [
    {
      "query_id": "f10_001",
      "query_text": "The trophy doesn't fit in the suitcase because it is too large. What is too large?",
      "expected_answer": "the trophy",
      "domain": "coreference",
      "task_family": "f10_confidence_calibration",
      "systems": [
        {
          "system": "LLM",
          "response": "the trophy",
          "execution_time": 2.5934979915618896,
          "success": true,
          "coherence_score": null,
          "error": null,
          "correct": true
        },
        {
          "system": "LLM+RAG",
          "response": "The trophy is too large.",
          "execution_time": 2.6248958110809326,
          "success": true,
          "coherence_score": null,
          "retrieval_enabled": true,
          "error": null,
          "correct": true
        },
        {
          "system": "RCE-LLM",
          "response": "The trophy.",
          "execution_time": 2.3995461463928223,
          "success": true,
          "coherence_score": 1.0,
          "coherence_modules": [
            "units",
            "temporal",
            "arithmetic",
            "coreference",
            "entailment",
            "computation"
          ],
          "pipeline_trace": null,
          "error": null,
          "correct": true
        }
      ]
    },
    {
      "query_id": "f10_002",
      "query_text": "The city councilmen refused the demonstrators a permit because they feared violence. Who feared violence?",
      "expected_answer": "the councilmen",
      "domain": "coreference",
      "task_family": "f10_confidence_calibration",
      "systems": [
        {
          "system": "LLM",
          "response": "The city councilmen.",
          "execution_time": 2.314255952835083,
          "success": true,
          "coherence_score": null,
          "error": null,
          "correct": false
        },
        {
          "system": "LLM+RAG",
          "response": "The city councilmen feared violence.",
          "execution_time": 2.8216161727905273,
          "success": true,
          "coherence_score": null,
          "retrieval_enabled": true,
          "error": null,
          "correct": false
        },
        {
          "system": "RCE-LLM",
          "response": "The city councilmen.",
          "execution_time": 2.447052001953125,
          "success": true,
          "coherence_score": 1.0,
          "coherence_modules": [
            "units",
            "temporal",
            "arithmetic",
            "coreference",
            "entailment",
            "computation"
          ],
          "pipeline_trace": null,
          "error": null,
          "correct": false
        }
      ]
    },
    {
      "query_id": "f10_003",
      "query_text": "A bat and ball cost $1.10 total. The bat costs $1.00 more than the ball. How much does the ball cost?",
      "expected_answer": "0.05",
      "domain": "arithmetic",
      "task_family": "f10_confidence_calibration",
      "systems": [
        {
          "system": "LLM",
          "response": "$0.05",
          "execution_time": 3.2749922275543213,
          "success": true,
          "coherence_score": null,
          "error": null,
          "correct": true
        },
        {
          "system": "LLM+RAG",
          "response": "",
          "execution_time": 2.4688053131103516,
          "success": true,
          "coherence_score": null,
          "retrieval_enabled": true,
          "error": null,
          "correct": false
        },
        {
          "system": "RCE-LLM",
          "response": "$0.05",
          "execution_time": 2.3730640411376953,
          "success": true,
          "coherence_score": 0.9647058823529413,
          "coherence_modules": [
            "units",
            "temporal",
            "arithmetic",
            "coreference",
            "entailment",
            "computation"
          ],
          "pipeline_trace": null,
          "error": null,
          "correct": true
        }
      ]
    },
    {
      "query_id": "f10_004",
      "query_text": "If 5 machines take 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?",
      "expected_answer": "5",
      "domain": "arithmetic",
      "task_family": "f10_confidence_calibration",
      "systems": [
        {
          "system": "LLM",
          "response": "5 minutes.",
          "execution_time": 2.400736093521118,
          "success": true,
          "coherence_score": null,
          "error": null,
          "correct": true
        },
        {
          "system": "LLM+RAG",
          "response": "5 minutes.",
          "execution_time": 2.287813901901245,
          "success": true,
          "coherence_score": null,
          "retrieval_enabled": true,
          "error": null,
          "correct": true
        },
        {
          "system": "RCE-LLM",
          "response": "5 minutes.",
          "execution_time": 2.4185609817504883,
          "success": true,
          "coherence_score": 1.0,
          "coherence_modules": [
            "units",
            "temporal",
            "arithmetic",
            "coreference",
            "entailment",
            "computation"
          ],
          "pipeline_trace": null,
          "error": null,
          "correct": true
        }
      ]
    },
    {
      "query_id": "f10_005",
      "query_text": "In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take for the patch to cover half the lake?",
      "expected_answer": "47",
      "domain": "arithmetic",
      "task_family": "f10_confidence_calibration",
      "systems": [
        {
          "system": "LLM",
          "response": "47 days",
          "execution_time": 2.409118175506592,
          "success": true,
          "coherence_score": null,
          "error": null,
          "correct": true
        },
        {
          "system": "LLM+RAG",
          "response": "47 days.",
          "execution_time": 2.2638070583343506,
          "success": true,
          "coherence_score": null,
          "retrieval_enabled": true,
          "error": null,
          "correct": true
        },
        {
          "system": "RCE-LLM",
          "response": "47 days",
          "execution_time": 2.526082992553711,
          "success": true,
          "coherence_score": 1.0,
          "coherence_modules": [
            "units",
            "temporal",
            "arithmetic",
            "coreference",
            "entailment",
            "computation"
          ],
          "pipeline_trace": null,
          "error": null,
          "correct": true
        }
      ]
    }
  ],
  "accuracy": {
    "LLM": 0.8,
    "LLM+RAG": 0.6,
    "RCE-LLM": 0.8
  }
}