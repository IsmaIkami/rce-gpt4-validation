<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RCE-GPT-4: Empirical Validation Results - Hallucination Benchmarks (F6-F12)</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --success-color: #27ae60;
            --warning-color: #f39c12;
            --danger-color: #e74c3c;
            --bg-color: #f8f9fa;
            --card-bg: #ffffff;
            --border-color: #dee2e6;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--primary-color);
            background-color: var(--bg-color);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            color: white;
            padding: 40px 0;
            text-align: center;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .metadata {
            background: var(--card-bg);
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .metadata h2 {
            color: var(--secondary-color);
            margin-bottom: 15px;
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 10px;
        }

        .metadata-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }

        .metadata-item {
            padding: 10px;
            background: var(--bg-color);
            border-radius: 4px;
        }

        .metadata-item strong {
            color: var(--primary-color);
            display: block;
            margin-bottom: 5px;
        }

        .summary-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }

        .card {
            background: var(--card-bg);
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            text-align: center;
        }

        .card h3 {
            color: var(--secondary-color);
            margin-bottom: 15px;
        }

        .card .value {
            font-size: 2.5em;
            font-weight: bold;
            margin: 10px 0;
        }

        .task-family {
            background: var(--card-bg);
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .task-family h3 {
            color: var(--secondary-color);
            margin-bottom: 20px;
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 10px;
        }

        .accuracy-bars {
            margin: 20px 0;
        }

        .accuracy-bar {
            margin: 15px 0;
        }

        .accuracy-bar-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-weight: 600;
        }

        .accuracy-bar-container {
            background: var(--border-color);
            height: 30px;
            border-radius: 15px;
            overflow: hidden;
        }

        .accuracy-bar-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--success-color), var(--secondary-color));
            transition: width 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 10px;
            color: white;
            font-weight: bold;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .comparison-table th,
        .comparison-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }

        .comparison-table th {
            background: var(--secondary-color);
            color: white;
            font-weight: 600;
        }

        .comparison-table tr:hover {
            background: var(--bg-color);
        }

        footer {
            margin-top: 50px;
            padding: 20px 0;
            text-align: center;
            color: #666;
            border-top: 1px solid var(--border-color);
        }

        .badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.9em;
            font-weight: 600;
            margin: 2px;
        }

        .badge-success {
            background: var(--success-color);
            color: white;
        }

        .badge-warning {
            background: var(--warning-color);
            color: white;
        }

        .badge-danger {
            background: var(--danger-color);
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>RCE-GPT-4: Empirical Validation Results</h1>
            <p>Hallucination Benchmarks (F6-F12) - RCE v0.6.0</p>
            <p><small>Author: Ismail Sialyen | DOI: 10.5281/zenodo.17360372</small></p>
        </div>
    </header>

    <div class="container">
        <section class="metadata">
            <h2>Benchmark Metadata</h2>
            <div class="metadata-grid">
                <div class="metadata-item">
                    <strong>Model</strong>
                    openai/gpt-oss-120b
                </div>
                <div class="metadata-item">
                    <strong>Execution Date</strong>
                    2025-11-15
                </div>
                <div class="metadata-item">
                    <strong>Total Queries</strong>
                    45 (F6-F12: 25 baseline + 20 RCE v0.6.0)
                </div>
                <div class="metadata-item">
                    <strong>Systems Tested</strong>
                    LLM, LLM+RAG, RCE-LLM
                </div>
            </div>
        </section>

        <h2 style="margin-bottom: 20px;">Overall Accuracy Summary (F6-F12)</h2>
        <div class="summary-cards">
            <div class="card">
                <h3>LLM (GPT-4 Baseline)</h3>
                <div class="value" style="color: var(--warning-color);">51.1%</div>
                <p>Standalone GPT-4 120B (no RCE)</p>
            </div>
            <div class="card">
                <h3>LLM+RAG (GPT-4 + Retrieval)</h3>
                <div class="value" style="color: var(--warning-color);">46.7%</div>
                <p>GPT-4 120B with RAG (no RCE)</p>
            </div>
            <div class="card">
                <h3>RCE-LLM (GPT-4 + RCE v0.6.0)</h3>
                <div class="value" style="color: var(--success-color);">70.4%</div>
                <p>GPT-4 120B with RCE v0.6.0 validation</p>
            </div>
        </div>

        <section class="metadata" style="margin-bottom: 30px;">
            <h2>RCE v0.6.0 Improvement Highlights</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px;">
                <div style="background: linear-gradient(135deg, #27ae60, #2ecc71); color: white; padding: 20px; border-radius: 8px; text-align: center;">
                    <h3 style="color: white; margin-bottom: 10px;">F12: Logical Fallacies</h3>
                    <div style="font-size: 2.5em; font-weight: bold;">80%</div>
                    <p>Detection rate - Primary use case validated</p>
                    <p><strong>LLM Baseline:</strong> 50%</p>
                </div>
                <div style="background: linear-gradient(135deg, #3498db, #5dade2); color: white; padding: 20px; border-radius: 8px; text-align: center;">
                    <h3 style="color: white; margin-bottom: 10px;">F11: Complex Reasoning</h3>
                    <div style="font-size: 2.5em; font-weight: bold;">67%</div>
                    <p>Detection rate - Bonus benefit</p>
                    <p><strong>LLM Baseline:</strong> 10%</p>
                </div>
            </div>
        </section>

        <h2 style="margin-bottom: 20px;">Task Family Results</h2>

        <div class="task-family">
            <h3>F6 Contradictory Reasoning</h3>
            <p><strong>Total Queries:</strong> 5</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>100.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 100.0%">
                            100.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>80.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 80.0%">
                            80.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE)</span>
                        <span>100.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 100.0%">
                            100.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F7 Temporal Reasoning</h3>
            <p><strong>Total Queries:</strong> 5</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F8 Arithmetic Hallucination</h3>
            <p><strong>Total Queries:</strong> 5</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F9 Noisy Rag</h3>
            <p><strong>Total Queries:</strong> 5</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>40.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 40.0%">
                            40.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>40.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 40.0%">
                            40.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE)</span>
                        <span>40.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 40.0%">
                            40.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F10 Confidence Calibration</h3>
            <p><strong>Total Queries:</strong> 5</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>80.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 80.0%">
                            80.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>60.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 60.0%">
                            60.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE)</span>
                        <span>80.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 80.0%">
                            80.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F11 Truthfulqa Misconceptions - Complex Multi-Step Reasoning</h3>
            <p><strong>Total Queries:</strong> 10</p>
            <p><strong>Description:</strong> Complex reasoning tasks requiring multi-step logic. RCE v0.6.0 detects 67% of errors despite not being designed for this task family.</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>10.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 10.0%">
                            10.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>10.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 10.0%">
                            10.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE v0.6.0)</span>
                        <span>67.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 67.0%">
                            67.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="task-family">
            <h3>F12 RCE Hallucination Reduction - Logical Fallacies</h3>
            <p><strong>Total Queries:</strong> 10</p>
            <p><strong>Description:</strong> Simple logical fallacies (affirming consequent). RCE v0.6.0 primary use case - detects 80% of logical fallacies, exceeding 60% target.</p>

            <div class="accuracy-bars">
                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM (GPT-4 Baseline)</span>
                        <span>50.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 50.0%">
                            50.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>LLM+RAG (GPT-4 + Retrieval)</span>
                        <span>50.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 50.0%">
                            50.0%
                        </div>
                    </div>
                </div>

                <div class="accuracy-bar">
                    <div class="accuracy-bar-label">
                        <span>RCE-LLM (GPT-4 + RCE v0.6.0)</span>
                        <span>80.0%</span>
                    </div>
                    <div class="accuracy-bar-container">
                        <div class="accuracy-bar-fill" style="width: 80.0%">
                            80.0%
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <section class="metadata">
            <h2>Key Findings - RCE v0.6.0 Performance</h2>
            <ul style="list-style-position: inside; line-height: 2;">
                <li><strong>RCE Version:</strong> v0.6.0 - Significantly improved hallucination detection</li>
                <li><strong>F12 Logical Fallacies:</strong> 80% detection rate (0% ‚Üí 80% improvement from v0.1.5)</li>
                <li><strong>F11 Complex Reasoning:</strong> 67% detection rate (0% ‚Üí 67% improvement from v0.1.5)</li>
                <li><strong>LLM Baseline Performance:</strong> F12: 50%, F11: 10% (F11 is significantly harder)</li>
                <li><strong>Key Insight:</strong> RCE v0.6.0 excels at detecting logical fallacies (primary design goal) and unexpectedly detects 2 out of 3 complex reasoning errors</li>
                <li><strong>Validation:</strong> Real API calls tested with GPT-4 via Groq</li>
            </ul>
        </section>

        <section class="metadata">
            <h2>Cross-Model Comparison: Llama 70B vs GPT-4 120B</h2>
            <p style="margin-bottom: 20px;">Direct comparison of identical benchmarks across two foundation models demonstrates how RCE validation performs across different LLM architectures. GPT-4 results updated with RCE v0.6.0.</p>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>System</th>
                        <th>Llama 70B (RCE v0.1.5)</th>
                        <th>GPT-4 120B (RCE v0.6.0)</th>
                        <th>Œî Difference</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>LLM Baseline</strong></td>
                        <td>52.0%</td>
                        <td>51.1%</td>
                        <td style="color: var(--danger-color)">
                            -0.9%
                        </td>
                    </tr>
                    <tr>
                        <td><strong>LLM+RAG</strong></td>
                        <td>36.0%</td>
                        <td>46.7%</td>
                        <td style="color: var(--success-color)">
                            +10.7%
                        </td>
                    </tr>
                    <tr>
                        <td><strong>RCE-LLM</strong></td>
                        <td>72.0%</td>
                        <td>70.4%</td>
                        <td style="color: var(--danger-color)">
                            -1.6%
                        </td>
                    </tr>
                </tbody>
            </table>

            <h3 style="margin-top: 30px;">How RCE Helps Both Models</h3>
            <ul style="list-style-position: inside; line-height: 2;">
                <li><strong>Llama 70B with RCE v0.1.5:</strong> +20.0% improvement over baseline (52.0% ‚Üí 72.0%)</li>
                <li><strong>GPT-4 120B with RCE v0.6.0:</strong> +19.3% improvement over baseline (51.1% ‚Üí 70.4%)</li>
                <li><strong>Consistency:</strong> RCE provides similar ~20% improvement across different architectures and versions</li>
                <li><strong>RAG Impact:</strong> GPT-4 shows better RAG performance than Llama (46.7% vs 36.0%)</li>
                <li><strong>Version Comparison:</strong> RCE v0.6.0 (GPT-4) performs comparably to v0.1.5 (Llama) with 70.4% vs 72.0% accuracy</li>
            </ul>
        </section>

        <section class="metadata">
            <h2>Cloud Resource Usage (Groq API)</h2>
            <div class="metadata-grid">
                <div class="metadata-item">
                    <strong>Total API Calls</strong>
                    150 calls (75 queries across 3 systems)
                </div>
                <div class="metadata-item">
                    <strong>Total Tokens</strong>
                    18,161 tokens
                </div>
                <div class="metadata-item">
                    <strong>Prompt Tokens</strong>
                    10,420 tokens
                </div>
                <div class="metadata-item">
                    <strong>Completion Tokens</strong>
                    7,741 tokens
                </div>
                <div class="metadata-item">
                    <strong>Execution Time</strong>
                    1.2 minutes total
                </div>
                <div class="metadata-item">
                    <strong>Cost Efficiency</strong>
                    ~$0.01-0.02 estimated cost via Groq
                </div>
            </div>

            <h3 style="margin-top: 20px;">Resource Comparison: Local vs Cloud</h3>
            <ul style="list-style-position: inside; line-height: 2;">
                <li><strong>Llama 70B (Local Ollama):</strong> Zero cloud costs, local compute resources only</li>
                <li><strong>GPT-4 120B (Groq API):</strong> 18,161 tokens total, minimal cloud cost (~$0.01-0.02)</li>
                <li><strong>Speed Advantage:</strong> Groq API averages 0.2-1.5s per query vs Llama local execution</li>
                <li><strong>Trade-off:</strong> Groq offers fast cloud inference at low cost vs Llama's zero-cost local deployment</li>
            </ul>
        </section>

        <!-- Reproduction Information -->
        <div class="results-section">
            <h2>Reproduction Instructions</h2>
            <div class="reproduction">
                <h3>How to Reproduce These Results</h3>
                <p>To reproduce the GPT-4 120B validation benchmark with RCE v0.6.0:</p>
                <ol style="margin-left: 20px; line-height: 2; margin-top: 10px;">
                    <li>Clone repository: <code>gh repo clone IsmaIkami/rce-gpt4-validation</code></li>
                    <li>Install dependencies: <code>pip install -r requirements.txt</code></li>
                    <li>Start RCE API: <code>cd rce-deployment-v0.6.0-api && python main.py</code></li>
                    <li>Set Groq API key: <code>export GROQ_API_KEY="your_groq_api_key"</code></li>
                    <li>Run benchmark: <code>python3 scripts/run_benchmarks.py</code></li>
                </ol>
                <p style="margin-top: 15px;"><strong>Results location:</strong> <code>results/</code> (45 queries across F6-F12, 135 total system responses)</p>
                <p style="margin-top: 10px;"><strong>Model:</strong> GPT-4 120B accessed via Groq API (<code>openai/gpt-oss-120b</code>)</p>
                <p style="margin-top: 10px;"><strong>RCE Version:</strong> v0.6.0 - Improved hallucination detection</p>
                <p style="margin-top: 10px;"><strong>Key Results:</strong> F12 (80% detection), F11 (67% detection), Overall RCE accuracy: 70.4%</p>
            </div>
        </div>

        <!-- Download Links -->
        <div class="results-section">
            <h2>Raw Data Access for Peer Review</h2>
            <p>Complete results and logs available for verification and reproduction:</p>
            <ul style="margin: 20px 0; line-height: 2;">
                <li><a href="f6_contradictory_reasoning_results.json" download>f6_contradictory_reasoning_results.json</a> - F6 detailed results (5 queries)</li>
                <li><a href="f7_temporal_reasoning_results.json" download>f7_temporal_reasoning_results.json</a> - F7 detailed results (5 queries)</li>
                <li><a href="f8_arithmetic_hallucination_results.json" download>f8_arithmetic_hallucination_results.json</a> - F8 detailed results (5 queries)</li>
                <li><a href="f9_noisy_rag_results.json" download>f9_noisy_rag_results.json</a> - F9 detailed results (5 queries)</li>
                <li><a href="f10_confidence_calibration_results.json" download>f10_confidence_calibration_results.json</a> - F10 detailed results (5 queries)</li>
                <li><a href="f11_truthfulqa_misconceptions_results.json" download>f11_truthfulqa_misconceptions_results.json</a> - F11 detailed results (10 queries) - RCE v0.6.0</li>
                <li><a href="f12_rce_hallucination_reduction_results.json" download>f12_rce_hallucination_reduction_results.json</a> - F12 detailed results (10 queries) - RCE v0.6.0</li>
                <li><a href="benchmark_GPT4_COMPLETE.log" download>benchmark_GPT4_COMPLETE.log</a> - Complete execution log with all queries and responses</li>
                <li><a href="usage_report.json" download>usage_report.json</a> - Groq API token usage statistics</li>
            </ul>
        </div>

        <!-- Quick Actions -->
        <div class="results-section">
            <h2>Quick Actions</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin: 20px 0;">
                <a href="https://github.com/IsmaIkami/rce-gpt4-validation" target="_blank" style="display: block; padding: 20px; background: var(--secondary-color); color: white; text-decoration: none; border-radius: 8px; text-align: center; font-weight: bold; transition: background 0.3s;">
                    üìÅ View Repository
                </a>
                <a href="https://doi.org/10.5281/zenodo.17360372" target="_blank" style="display: block; padding: 20px; background: var(--success-color); color: white; text-decoration: none; border-radius: 8px; text-align: center; font-weight: bold; transition: background 0.3s;">
                    üìÑ Publication (DOI)
                </a>
                <a href="f12_rce_hallucination_reduction_results.json" download style="display: block; padding: 20px; background: var(--warning-color); color: white; text-decoration: none; border-radius: 8px; text-align: center; font-weight: bold; transition: background 0.3s;">
                    üíæ Download F12 Results
                </a>
                <a href="https://ismaikami.github.io/rce-llm-empirical-validation" target="_blank" style="display: block; padding: 20px; background: #9b59b6; color: white; text-decoration: none; border-radius: 8px; text-align: center; font-weight: bold; transition: background 0.3s;">
                    üî¨ Llama 70B Benchmark
                </a>
            </div>
        </div>

        <footer>
            <p><strong>RCE-GPT-4 Empirical Validation - Updated with RCE v0.6.0 Results</strong></p>
            <p>Last Updated: 2025-11-15 | F11 & F12 benchmarks with RCE v0.6.0</p>
            <p>Author: Ismail Sialyen | DOI: 10.5281/zenodo.17360372</p>
            <p><a href="https://github.com/IsmaIkami/rce-gpt4-validation" target="_blank">GitHub Repository</a> | <a href="https://ismaikami.github.io/rce-llm-empirical-validation" target="_blank">Llama 70B Benchmark</a></p>
        </footer>
    </div>
</body>
</html>
